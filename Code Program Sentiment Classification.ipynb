{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install Sastrawi\n",
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W04c9uuQ7Wz9",
        "outputId": "97e549e7-2952-48ae-e65f-1634942a02c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3v1EMkj7SwQ",
        "outputId": "37ee8f66-ecd1-4171-c597-eb14461f2fc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import emoji\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "\n",
        "import datetime as dt\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dense, Dropout, LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "daring = pd.read_csv('Daring_Tweets_Clean.csv')\n",
        "daring.info()\n",
        "daring.dropna(inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYeKxt1w7aNM",
        "outputId": "4fbdaa64-1eda-4a1c-bf10-b9febd090729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1561 entries, 0 to 1560\n",
            "Data columns (total 4 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   Tweet             1561 non-null   object \n",
            " 1   FINAL LABEL       1561 non-null   float64\n",
            " 2   Tweet_Preprocess  1561 non-null   object \n",
            " 3   Tweet_New         1560 non-null   object \n",
            "dtypes: float64(1), object(3)\n",
            "memory usage: 48.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = daring['Tweet_New'].values\n",
        "y = daring['FINAL LABEL'].values\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf_idf = TfidfVectorizer(ngram_range=(1,10))\n",
        "x = tf_idf.fit_transform(x)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y, random_state = 0)"
      ],
      "metadata": {
        "id": "E130A2tR7dzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "sm = SMOTE()\n",
        "X_smote, y_smote = sm.fit_resample(x, y)\n",
        "print(sorted(Counter(y_smote).items()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6JWjU6h7jKn",
        "outputId": "60fe5448-d49e-485a-8d21-0d90efd21f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(-1.0, 921), (0.0, 921), (1.0, 921)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_S, X_test_S, y_train_S, y_test_S = train_test_split(X_smote, y_smote, test_size = 0.2, stratify = y_smote, random_state = 0)"
      ],
      "metadata": {
        "id": "lKhCFiKi8nva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.neural_network import MLPClassifier\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.metrics import accuracy_score, f1_score\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "# rows = [0.0001,0.001,0.01,0.1]\n",
        "\n",
        "# for i in rows:\n",
        "#   for j in range(5, 45, 5):\n",
        "#     modelANN = MLPClassifier(hidden_layer_sizes = (j,j),\n",
        "#                           activation = \"logistic\",\n",
        "#                           batch_size = 30,\n",
        "#                           max_iter = 10000,\n",
        "#                           alpha = i,\n",
        "#                           random_state = 0)\n",
        "#     # start = timeit.default_timer()\n",
        "#     modelANN.fit(X_train_S, y_train_S)\n",
        "#     prediksi = modelANN.predict(X_test_S)\n",
        "#     # sheet.write(row,col,accuracy_score(y_test,prediksi))\n",
        "#     # stop = timeit.default_timer()\n",
        "#     # col = col + 1\n",
        "#     print(f\"{j},{i}=>{accuracy_score(y_test_S,prediksi)}\")\n",
        "#     # sheet.write(row,col,stop)\n"
      ],
      "metadata": {
        "id": "GYurHYVo8sGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.neural_network import MLPClassifier\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.metrics import accuracy_score, f1_score\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# modelANN = MLPClassifier(hidden_layer_sizes = (25 ,25),\n",
        "#                           activation = \"relu\",\n",
        "#                           batch_size = 30,\n",
        "#                           max_iter = 1000,\n",
        "#                           alpha = 0.0001,\n",
        "#                           random_state = 0)\n",
        "# modelANN.fit(X_train_S, y_train_S)\n",
        "# prediksi = modelANN.predict(X_test_S)\n",
        "# print(f\"{accuracy_score(y_test_S,prediksi)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jDKa1U9-m8B",
        "outputId": "1244e5ff-208c-4aad-df6e-a2972ccb815e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9276672694394213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "modelANN = MLPClassifier(hidden_layer_sizes = (25 ,25),\n",
        "                          activation = \"relu\",\n",
        "                          batch_size = 30,\n",
        "                          max_iter = 1000,\n",
        "                          alpha = 0.0001,\n",
        "                          random_state = 0)\n",
        "modelANN.fit(X_train, y_train)\n",
        "prediksi = modelANN.predict(X_test)\n",
        "print(f\"{accuracy_score(y_test,prediksi)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uCTuu43XgVu",
        "outputId": "32d440e5-125f-4fc3-cc7e-5cf004b40d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6410256410256411\n"
          ]
        }
      ]
    }
  ]
}